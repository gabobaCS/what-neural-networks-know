{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ec1698b4",
   "metadata": {},
   "source": [
    "### Extract Logits for Use in MSP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "02c918be",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n",
      "Loading dataset from E:\\datasets\\KNN-OOD\\Textures\\images...\n",
      "Using structured (ImageFolder) dataset loading\n",
      "Dataset size: 5640\n",
      "\n",
      "Extracting logits...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting logits: 100%|██████████| 45/45 [00:23<00:00,  1.88it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Saving logits to textures_logits.pt...\n",
      "Saved logits: torch.Size([5640, 1000])\n",
      "\n",
      "Done!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "from torchvision import transforms\n",
    "from torchvision.datasets import ImageFolder\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from tqdm import tqdm\n",
    "import os\n",
    "from PIL import Image\n",
    "from pathlib import Path\n",
    "\n",
    "# Setup device\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "# Define transforms\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize(256),\n",
    "    transforms.CenterCrop(224),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
    "                       std=[0.229, 0.224, 0.225])\n",
    "])\n",
    "\n",
    "def extract_logits(model, dataloader, device):\n",
    "    \"\"\"Extract logits from model for all samples in dataloader\"\"\"\n",
    "    all_logits = []\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for batch in tqdm(dataloader, desc=\"Extracting logits\"):\n",
    "            images, labels = batch\n",
    "            images = images.to(device)\n",
    "            logits = model(images)\n",
    "            all_logits.append(logits.cpu())\n",
    "    \n",
    "    return torch.cat(all_logits, dim=0)\n",
    "\n",
    "\n",
    "class FlatImageDataset(Dataset):\n",
    "    \"\"\"Dataset for loading all images from a flat directory structure\"\"\"\n",
    "    def __init__(self, root_dir, transform=None, extensions=('.jpg', '.jpeg', '.png', '.JPEG', '.JPG', '.PNG')):\n",
    "        self.root_dir = Path(root_dir)\n",
    "        self.transform = transform\n",
    "        \n",
    "        # Get all image files recursively\n",
    "        self.image_paths = []\n",
    "        for ext in extensions:\n",
    "            self.image_paths.extend(list(self.root_dir.rglob(f'*{ext}')))\n",
    "        \n",
    "        self.image_paths.sort()  # For reproducibility\n",
    "        print(f\"Found {len(self.image_paths)} images\")\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.image_paths)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        img_path = self.image_paths[idx]\n",
    "        try:\n",
    "            image = Image.open(img_path).convert('RGB')\n",
    "        except Exception as e:\n",
    "            print(f\"Error loading image {img_path}: {e}\")\n",
    "            # Return a blank image if loading fails\n",
    "            image = Image.new('RGB', (224, 224), color='black')\n",
    "        \n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "        \n",
    "        # Return dummy label (0) since we only care about logits for OOD detection\n",
    "        return image, 0\n",
    "\n",
    "\n",
    "def extract_and_save_logits(dataset_path, \n",
    "                            output_path, \n",
    "                            batch_size=128, \n",
    "                            num_workers=4, \n",
    "                            flat_structure=False):\n",
    "    \"\"\"\n",
    "    Extract logits from a dataset and save to file\n",
    "    \n",
    "    Args:\n",
    "        dataset_path: Path to the dataset directory\n",
    "        output_path: Path where to save the logits .pt file\n",
    "        batch_size: Batch size for processing\n",
    "        num_workers: Number of workers for data loading\n",
    "        flat_structure: If False (default), expects ImageFolder structure with class subdirectories.\n",
    "                       If True, loads all images from directory recursively (flat structure).\n",
    "    \"\"\"\n",
    "    # Load pre-trained ResNet-50\n",
    "    model = torchvision.models.resnet50(pretrained=True)\n",
    "    model = model.to(device)\n",
    "    model.eval()\n",
    "    \n",
    "    # Load dataset\n",
    "    print(f\"Loading dataset from {dataset_path}...\")\n",
    "    print(f\"Using {'flat' if flat_structure else 'structured (ImageFolder)'} dataset loading\")\n",
    "    \n",
    "    if flat_structure:\n",
    "        dataset = FlatImageDataset(dataset_path, transform=transform)\n",
    "    else:\n",
    "        dataset = ImageFolder(dataset_path, transform=transform)\n",
    "    \n",
    "    print(f\"Dataset size: {len(dataset)}\")\n",
    "    \n",
    "    # Create dataloader\n",
    "    dataloader = DataLoader(dataset, batch_size=batch_size, shuffle=False, num_workers=num_workers)\n",
    "    \n",
    "    # Extract logits\n",
    "    print(f\"\\nExtracting logits...\")\n",
    "    logits = extract_logits(model, dataloader, device)\n",
    "    \n",
    "    # Save logits\n",
    "    print(f\"\\nSaving logits to {output_path}...\")\n",
    "    torch.save(logits, output_path)\n",
    "    print(f\"Saved logits: {logits.shape}\")\n",
    "    \n",
    "    return logits\n",
    "\n",
    "\n",
    "# Example usage:\n",
    "if __name__ == \"__main__\":\n",
    "    # Example 1: Structured dataset (ImageFolder format with class subdirectories)\n",
    "    # extract_and_save_logits(\n",
    "    #     dataset_path='/path/to/imagenet/val',\n",
    "    #     output_path='imagenet_val_logits.pt',\n",
    "    #     flat_structure=False  # Uses ImageFolder\n",
    "    # )\n",
    "    \n",
    "    # Example 2: Flat dataset (all images in one directory or nested without class structure)\n",
    "    DATASET_PATH = r'E:\\datasets\\KNN-OOD\\Textures\\images'\n",
    "    OUTPUT_PATH = 'textures_logits.pt'\n",
    "    \n",
    "    extract_and_save_logits(\n",
    "        dataset_path=DATASET_PATH,\n",
    "        output_path=OUTPUT_PATH,\n",
    "        batch_size=128,\n",
    "        num_workers=0,\n",
    "        flat_structure=False  # Set to True for flat directory structure\n",
    "    )\n",
    "    \n",
    "    print(\"\\nDone!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a517993c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading ID data from: imagenet1k_logits.pt\n",
      "ID data: 50000 samples, 1000 classes\n",
      "ID MSP: min=0.0191, max=1.0000, mean=0.7970\n",
      "\n",
      "Evaluating on iNaturalist...\n",
      "  iNaturalist: FPR95=52.82%, AUROC=88.39%\n",
      "Evaluating on SUN...\n",
      "  SUN: FPR95=69.11%, AUROC=81.64%\n",
      "Evaluating on Places...\n",
      "  Places: FPR95=72.07%, AUROC=80.53%\n",
      "Evaluating on Textures...\n",
      "  Textures: FPR95=66.26%, AUROC=80.43%\n",
      "\n",
      "============================================================\n",
      "Average: FPR95=65.06%, AUROC=82.75%\n",
      "============================================================\n",
      "\n",
      "======================================================================\n",
      "OOD Dataset               FPR95 ↓      AUROC ↑      Samples\n",
      "----------------------------------------------------------------------\n",
      "iNaturalist                52.82%       88.39%        20000\n",
      "SUN                        69.11%       81.64%        20000\n",
      "Places                     72.07%       80.53%        20000\n",
      "Textures                   66.26%       80.43%         5640\n",
      "----------------------------------------------------------------------\n",
      "Average                    65.06%       82.75%            -\n",
      "======================================================================\n",
      "\n",
      "Access results:\n",
      "iNaturalist FPR95: 52.82%\n",
      "SUN FPR95: 69.11%\n",
      "Places FPR95: 72.07%\n",
      "Textures FPR95: 66.26%\n",
      "Average AUROC: 82.75%\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from sklearn.metrics import roc_auc_score, roc_curve\n",
    "\n",
    "\n",
    "def compute_msp_scores(logits):\n",
    "    \"\"\"Compute Maximum Softmax Probability scores.\"\"\"\n",
    "    if isinstance(logits, np.ndarray):\n",
    "        logits_tensor = torch.from_numpy(logits).float()\n",
    "    else:\n",
    "        logits_tensor = logits.float()\n",
    "    \n",
    "    probs = F.softmax(logits_tensor, dim=-1)\n",
    "    msp_scores = probs.max(dim=-1).values.numpy()\n",
    "    return msp_scores\n",
    "\n",
    "\n",
    "def compute_auroc(id_scores, ood_scores):\n",
    "    \"\"\"Compute AUROC (higher is better).\"\"\"\n",
    "    scores = np.concatenate([id_scores, ood_scores])\n",
    "    labels = np.concatenate([np.ones(len(id_scores)), np.zeros(len(ood_scores))])\n",
    "    return roc_auc_score(labels, scores) * 100\n",
    "\n",
    "\n",
    "def compute_fpr95(id_scores, ood_scores):\n",
    "    \"\"\"Compute FPR when TPR=95% (lower is better).\"\"\"\n",
    "    scores = np.concatenate([id_scores, ood_scores])\n",
    "    labels = np.concatenate([np.ones(len(id_scores)), np.zeros(len(ood_scores))])\n",
    "    \n",
    "    fpr, tpr, _ = roc_curve(labels, scores, pos_label=1)\n",
    "    idx = np.argmax(tpr >= 0.95)\n",
    "    return fpr[idx] * 100\n",
    "\n",
    "\n",
    "def load_logits(path):\n",
    "    \"\"\"\n",
    "    Load logits from either .pt or .npy file.\n",
    "    Handles both your format and KNN-OOD format.\n",
    "    \"\"\"\n",
    "    if path.endswith('.pt'):\n",
    "        # Your format: torch.save(logits, path)\n",
    "        logits = torch.load(path, map_location='cpu')\n",
    "        if isinstance(logits, torch.Tensor):\n",
    "            logits = logits.numpy()\n",
    "    elif path.endswith('.npy'):\n",
    "        # KNN-OOD format: (feat_log, score_log, label_log)\n",
    "        data = np.load(path, allow_pickle=True)\n",
    "        if len(data) == 3:\n",
    "            _, score_log, _ = data\n",
    "        elif len(data) == 2:\n",
    "            _, score_log = data\n",
    "        else:\n",
    "            # Assume it's just raw logits\n",
    "            score_log = data\n",
    "        logits = score_log.T if score_log.shape[0] < score_log.shape[1] else score_log\n",
    "        logits = logits.astype(np.float32)\n",
    "    else:\n",
    "        raise ValueError(f\"Unsupported file format: {path}\")\n",
    "    \n",
    "    return logits\n",
    "\n",
    "\n",
    "def evaluate_msp_ood(id_data_path, ood_data_dict):\n",
    "    \"\"\"Evaluate MSP on ID and multiple OOD datasets.\"\"\"\n",
    "    # Load ID data and compute MSP scores\n",
    "    print(f\"Loading ID data from: {id_data_path}\")\n",
    "    id_logits = load_logits(id_data_path)\n",
    "    \n",
    "    # Ensure correct shape: (num_samples, num_classes)\n",
    "    if id_logits.shape[1] > 1000:  # Likely transposed\n",
    "        id_logits = id_logits.T\n",
    "    \n",
    "    id_msp_scores = compute_msp_scores(id_logits)\n",
    "    \n",
    "    print(f\"ID data: {id_logits.shape[0]} samples, {id_logits.shape[1]} classes\")\n",
    "    print(f\"ID MSP: min={id_msp_scores.min():.4f}, max={id_msp_scores.max():.4f}, mean={id_msp_scores.mean():.4f}\\n\")\n",
    "    \n",
    "    # Evaluate on each OOD dataset\n",
    "    results = {}\n",
    "    \n",
    "    for ood_name, ood_path in ood_data_dict.items():\n",
    "        print(f\"Evaluating on {ood_name}...\")\n",
    "        \n",
    "        # Load OOD data\n",
    "        ood_logits = load_logits(ood_path)\n",
    "        \n",
    "        # Ensure correct shape\n",
    "        if ood_logits.shape[1] > 1000:\n",
    "            ood_logits = ood_logits.T\n",
    "        \n",
    "        ood_msp_scores = compute_msp_scores(ood_logits)\n",
    "        \n",
    "        # Compute metrics\n",
    "        auroc = compute_auroc(id_msp_scores, ood_msp_scores)\n",
    "        fpr95 = compute_fpr95(id_msp_scores, ood_msp_scores)\n",
    "        \n",
    "        results[ood_name] = {'fpr95': fpr95, 'auroc': auroc, 'num_samples': len(ood_logits)}\n",
    "        print(f\"  {ood_name}: FPR95={fpr95:.2f}%, AUROC={auroc:.2f}%\")\n",
    "    \n",
    "    # Compute averages\n",
    "    avg_fpr95 = np.mean([r['fpr95'] for r in results.values()])\n",
    "    avg_auroc = np.mean([r['auroc'] for r in results.values()])\n",
    "    results['average'] = {'fpr95': avg_fpr95, 'auroc': avg_auroc}\n",
    "    \n",
    "    print(f\"\\n{'='*60}\")\n",
    "    print(f\"Average: FPR95={avg_fpr95:.2f}%, AUROC={avg_auroc:.2f}%\")\n",
    "    print(f\"{'='*60}\")\n",
    "    \n",
    "    # Print table\n",
    "    print(f\"\\n{'='*70}\")\n",
    "    print(f\"{'OOD Dataset':<20} {'FPR95 ↓':>12} {'AUROC ↑':>12} {'Samples':>12}\")\n",
    "    print(f\"{'-'*70}\")\n",
    "    for ood_name, metrics in results.items():\n",
    "        if ood_name == 'average':\n",
    "            continue\n",
    "        print(f\"{ood_name:<20} {metrics['fpr95']:>11.2f}% {metrics['auroc']:>11.2f}% {metrics['num_samples']:>12}\")\n",
    "    print(f\"{'-'*70}\")\n",
    "    print(f\"{'Average':<20} {avg_fpr95:>11.2f}% {avg_auroc:>11.2f}% {'-':>12}\")\n",
    "    print(f\"{'='*70}\\n\")\n",
    "    \n",
    "    return results\n",
    "\n",
    "\n",
    "# ============================================================================\n",
    "# USAGE: Replace with your actual .pt file paths\n",
    "# ============================================================================\n",
    "\n",
    "# Your ID dataset (e.g., ImageNet validation set)\n",
    "id_data_path = \"imagenet1k_logits.pt\"\n",
    "\n",
    "# Your OOD datasets\n",
    "ood_data_dict = {\n",
    "    \"iNaturalist\": \"selected_inaturalist21_logits.pt\",\n",
    "    \"SUN\": \"sun_logits.pt\",\n",
    "    \"Places\": \"places_logits.pt\",\n",
    "    \"Textures\": \"textures_logits.pt\",\n",
    "}\n",
    "\n",
    "# Run evaluation\n",
    "results = evaluate_msp_ood(id_data_path, ood_data_dict)\n",
    "\n",
    "# Access individual results\n",
    "print(\"Access results:\")\n",
    "for ood_name in ood_data_dict.keys():\n",
    "    print(f\"{ood_name} FPR95: {results[ood_name]['fpr95']:.2f}%\")\n",
    "print(f\"Average AUROC: {results['average']['auroc']:.2f}%\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env (3.12.0)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
